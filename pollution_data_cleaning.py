# -*- coding: utf-8 -*-
"""pollution_data_cleaning.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1KlDmbIFcLMdfE2b5PhC4axJrnWIiinOS
"""

import kagglehub

# Download latest version
path = kagglehub.dataset_download("alpacanonymous/us-pollution-20002021")

print("Path to dataset files:", path)

import pandas as pd
import os

print(os.listdir(path))

pollution_df = pd.read_csv(os.path.join(path, "pollution_2000_2021.csv"))

pollution_df.head()

value_cols = [
    c for c in pollution_df.columns
    if c.endswith("Mean") or c.endswith("AQI")
]

to_keep = [
    "Date", "Year", "Month", "Day",
    "State", "County", "City"
] + value_cols

def month_to_season(m):
    if m in (12, 1, 2):
        return "Winter"
    elif m in (3, 4, 5):
        return "Spring"
    elif m in (6, 7, 8):
        return "Summer"
    else:
        return "Fall"

clean_df = pollution_df[to_keep].copy()

clean_df["Season"] = clean_df["Month"].apply(month_to_season)

clean_df.head()

clean_df['State'].nunique()

row_count = len(clean_df)
row_count

clean_df = clean_df.dropna().reset_index(drop=True)

row_count = len(clean_df)
row_count

!pip install psycopg2-binary sqlalchemy

from sqlalchemy import create_engine

host     = 'database-1.cyljtjkkhdgh.us-east-1.rds.amazonaws.com'
dbname   = 'postgres'
user     = 'postgres'
password = 'database1234'
port     = 5432

engine = create_engine(
    f'postgresql://{user}:{password}@{host}:{port}/{dbname}'
)

# Push your cleaned DataFrame
clean_df.to_sql(
    'pollution_data',
    engine,
    if_exists='replace',
    index=False
)