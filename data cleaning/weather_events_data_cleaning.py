# -*- coding: utf-8 -*-
"""weather_events_data_cleaning.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Mh8l4ShAnfyHi6y3glgfesDyE3jo2quQ
"""

import kagglehub

# Download latest version
path = kagglehub.dataset_download("sobhanmoosavi/us-weather-events")

print("Path to dataset files:", path)

import pandas as pd
import os

print(os.listdir(path))

df = pd.read_csv(os.path.join(path, "WeatherEvents_Jan2016-Dec2022.csv"))

print("Unique raw states:", df['State'].unique())

state_abbr_to_name = {
    'AL': 'Alabama', 'AK': 'Alaska', 'AZ': 'Arizona', 'AR': 'Arkansas',
    'CA': 'California', 'CO': 'Colorado', 'CT': 'Connecticut', 'DE': 'Delaware',
    'FL': 'Florida', 'GA': 'Georgia', 'HI': 'Hawaii', 'ID': 'Idaho',
    'IL': 'Illinois', 'IN': 'Indiana', 'IA': 'Iowa', 'KS': 'Kansas',
    'KY': 'Kentucky', 'LA': 'Louisiana', 'ME': 'Maine', 'MD': 'Maryland',
    'MA': 'Massachusetts', 'MI': 'Michigan', 'MN': 'Minnesota', 'MS': 'Mississippi',
    'MO': 'Missouri', 'MT': 'Montana', 'NE': 'Nebraska', 'NV': 'Nevada',
    'NH': 'New Hampshire', 'NJ': 'New Jersey', 'NM': 'New Mexico', 'NY': 'New York',
    'NC': 'North Carolina', 'ND': 'North Dakota', 'OH': 'Ohio', 'OK': 'Oklahoma',
    'OR': 'Oregon', 'PA': 'Pennsylvania', 'RI': 'Rhode Island', 'SC': 'South Carolina',
    'SD': 'South Dakota', 'TN': 'Tennessee', 'TX': 'Texas', 'UT': 'Utah',
    'VT': 'Vermont', 'VA': 'Virginia', 'WA': 'Washington', 'WV': 'West Virginia',
    'WI': 'Wisconsin', 'WY': 'Wyoming'
}

# Apply the mapping to your weather DataFrame
df['State'] = df['State'].astype(str).str.strip()
df['State'] = df['State'].str.extract(r'^([A-Z]{2})')
df['State'] = df['State'].map(state_abbr_to_name)

df.head()

print("Unique raw states:", df['State'].unique())

df['StartDate'] = pd.to_datetime(df['StartTime(UTC)']).dt.date
df_clean = df.drop(columns=["StartTime(UTC)", "EndTime(UTC)", "City", "ZipCode"])
df_clean.columns = [
    'event_id', 'type', 'severity', 'precipitation', 'timezone',
    'airport_code', 'location_lat', 'location_lng',
    'county', 'state', 'start_date'
]
df_clean.head()

print(df_clean.isna().sum())

df_clean['start_date'] = pd.to_datetime(df_clean['start_date'])

# Define a function to assign seasons based on month
def get_season(month):
    if month in [12, 1, 2]:
        return 'Winter'
    elif month in [3, 4, 5]:
        return 'Spring'
    elif month in [6, 7, 8]:
        return 'Summer'
    else:
        return 'Fall'

df_clean['Season'] = df_clean['start_date'].dt.month.map(get_season)

df_clean.head()

import pandas as pd
import psycopg2

# Save to local CSV file on Colab's temporary disk
df_clean.to_csv("weather_events.csv", index=False, header=False)

# Connect to PostgreSQL
conn = psycopg2.connect(
    host='database-1.cyljtjkkhdgh.us-east-1.rds.amazonaws.com',
    dbname='postgres',
    user='postgres',
    password='database1234',
    port=5432,
    sslmode='require'
)

cur = conn.cursor()

# Drop + Create table
cur.execute("DROP TABLE IF EXISTS weather_events;")
cur.execute("""
CREATE TABLE weather_events (
    event_id TEXT,
    type TEXT,
    severity TEXT,
    precipitation NUMERIC,
    timezone TEXT,
    airport_code TEXT,
    location_lat NUMERIC,
    location_lng NUMERIC,
    county TEXT,
    state TEXT,
    start_date DATE,
    season TEXT
);
""")

# Open the file
with open("weather_events.csv", "r") as f:
    cur.copy_expert("COPY weather_events FROM STDIN WITH CSV", f)


conn.commit()
cur.close()
conn.close()

